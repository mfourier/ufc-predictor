{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09612b6-fe0c-4377-9380-b987af855909",
   "metadata": {},
   "source": [
    "# ðŸ”¹ UFC Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31623b35-b326-4446-b9d8-cebe5a2e9291",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d507bd6-e395-4e0f-b5e9-edfce56d629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set the project root directory\n",
    "project_root = '/home/mfourier/ufc-predictor'\n",
    "\n",
    "# Import Models\n",
    "sys.path.append(os.path.join(project_root, 'src/models'))\n",
    "import model_factory\n",
    "\n",
    "# Import Metrics\n",
    "sys.path.append(os.path.join(project_root, 'utils'))\n",
    "from metrics import validate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f90d7-9e24-4ac1-933c-0265aca44e38",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3348f1c8-09a3-4d23-98b0-f778068a5225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 6541 rows and 89 columns.\n"
     ]
    }
   ],
   "source": [
    "project_root = '/home/mfourier/ufc-predictor'\n",
    "file_path = f'{project_root}/data/processed/ufc_etl.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"Data loaded: {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c8e768-e0aa-4c97-b398-21d24c41900a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_train, df_test \u001b[38;5;241m=\u001b[39m random_data\u001b[38;5;241m.\u001b[39mrandom_ufc_data()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Separate training and testing sets\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Todas las columnas excepto la Ãºltima\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_train, df_test = random_data.random_ufc_data()\n",
    "\n",
    "# Separate training and testing sets\n",
    "X_train = df_train.iloc[:, :-1]  # Todas las columnas excepto la Ãºltima\n",
    "y_train = df_train.iloc[:, -1]   # Solo la Ãºltima columna\n",
    "\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c1712-e5f2-46c2-b41d-130f39b0fef4",
   "metadata": {},
   "source": [
    "## 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0fa52-2f28-4397-a1b5-98c994ddcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Get the KNN model from the model factory\n",
    "knn_model = model_factory.get_model('knn', X_train, y_train)\n",
    "\n",
    "# ðŸ”¹ Prediction with the KNN model\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# ðŸ”¹ Model evaluation using F1 score and other metrics through 'validate_model'\n",
    "accuracy, f1 = validate_model(knn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e7733-5a08-4eb3-af70-3d01de66b40c",
   "metadata": {},
   "source": [
    "## 4. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d09ea-718d-418b-a7c7-a0d2f64be037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ðŸ”¹ Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Fighter A\", \"Fighter B\"], yticklabels=[\"Fighter A\", \"Fighter B\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96f9c6-ec52-4466-a7e1-ce92d663a2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
