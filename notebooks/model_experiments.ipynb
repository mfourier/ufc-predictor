{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09612b6-fe0c-4377-9380-b987af855909",
   "metadata": {},
   "source": [
    "# ðŸ”¹ UFC Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31623b35-b326-4446-b9d8-cebe5a2e9291",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d507bd6-e395-4e0f-b5e9-edfce56d629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the project root\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Import from /src\n",
    "sys.path.append(os.path.join(project_root, 'src'))\n",
    "from utils.metrics import evaluate_model, compare_metrics, compare_parameters\n",
    "from utils.io_model import load_model\n",
    "from models.model_factory import model_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a652d2c8-5d08-471b-ac6c-19ceeeb65e6d",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b91ed0e-8432-4e84-a009-92d03f3f58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded: 6541 rows, 12 columns.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = os.path.join(project_root, 'data', 'processed', 'ufc_processed.csv')\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "ufc_data = pd.read_csv(file_path)\n",
    "print(f\"Data successfully loaded: {ufc_data.shape[0]} rows, {ufc_data.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f90d7-9e24-4ac1-933c-0265aca44e38",
   "metadata": {},
   "source": [
    "## 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3348f1c8-09a3-4d23-98b0-f778068a5225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Model loaded from: /home/mfourier/ufc-predictor/models/knn_best.pkl\n",
      "ðŸ“¦ Model loaded from: /home/mfourier/ufc-predictor/models/svm_best.pkl\n",
      "ðŸ“¦ Model loaded from: /home/mfourier/ufc-predictor/models/lr_best.pkl\n",
      "ðŸ“¦ Model loaded from: /home/mfourier/ufc-predictor/models/rf_best.pkl\n",
      "ðŸ“¦ Model loaded from: /home/mfourier/ufc-predictor/models/adaboost_best.pkl\n",
      "ðŸ“¦ Model loaded from: /home/mfourier/ufc-predictor/models/nb_best.pkl\n"
     ]
    }
   ],
   "source": [
    "model_names = ['knn_best', 'svm_best', 'lr_best', 'rf_best', 'adaboost_best', 'nb_best']\n",
    "pretty_names = ['KNN', 'SVM','Linear Regression', 'Random Forest', 'AdaBoost', 'Naive Bayes']\n",
    "model_pretty_dict = dict(zip(model_names, pretty_names))\n",
    "models_dict = {model_pretty_dict[name]: load_model(name) for name in model_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c1712-e5f2-46c2-b41d-130f39b0fef4",
   "metadata": {},
   "source": [
    "## 4. Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb50404-b86b-47ab-96f6-ec62ad5ca2c7",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31073e0-3eb2-4852-aeef-2f1822e11b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Best Parameters Found with GridSearch for KNN: {'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "ðŸš€ Best Parameters Found with GridSearch for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "ðŸš€ Best Parameters Found with GridSearch for Linear Regression: {'C': 0.01, 'solver': 'lbfgs'}\n",
      "ðŸš€ Best Parameters Found with GridSearch for Random Forest: {'max_depth': 5, 'n_estimators': 100}\n",
      "ðŸš€ Best Parameters Found with GridSearch for AdaBoost: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "ðŸš€ Best Parameters Found with GridSearch for Naive Bayes: {'var_smoothing': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "parameters = compare_parameters(models_dict, ufc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324291c-bb0b-4008-bdc7-62c2fa42278f",
   "metadata": {},
   "source": [
    "### Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f0fa52-2f28-4397-a1b5-98c994ddcfe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.565317</td>\n",
       "      <td>0.470383</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.321812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.582124</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.077572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.579068</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>0.177536</td>\n",
       "      <td>0.262383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.128623</td>\n",
       "      <td>0.206997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.585180</td>\n",
       "      <td>0.517928</td>\n",
       "      <td>0.235507</td>\n",
       "      <td>0.323786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.455115</td>\n",
       "      <td>0.394928</td>\n",
       "      <td>0.422890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Precision    Recall  F1 Score\n",
       "Model                                                     \n",
       "KNN                0.565317   0.470383  0.244565  0.321812\n",
       "SVM                0.582124   0.560976  0.041667  0.077572\n",
       "Linear Regression  0.579068   0.502564  0.177536  0.262383\n",
       "Random Forest      0.584416   0.529851  0.128623  0.206997\n",
       "AdaBoost           0.585180   0.517928  0.235507  0.323786\n",
       "Naive Bayes        0.545455   0.455115  0.394928  0.422890"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics = compare_metrics(models_dict, ufc_data)\n",
    "model_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
