{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09612b6-fe0c-4377-9380-b987af855909",
   "metadata": {},
   "source": [
    "# ðŸ”¹ UFC Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31623b35-b326-4446-b9d8-cebe5a2e9291",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d507bd6-e395-4e0f-b5e9-edfce56d629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the project root\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Import from /src\n",
    "sys.path.append(os.path.join(project_root, 'src'))\n",
    "from utils.metrics import evaluate_model\n",
    "from models.model_factory import model_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f90d7-9e24-4ac1-933c-0265aca44e38",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3348f1c8-09a3-4d23-98b0-f778068a5225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded: 6541 rows, 89 columns.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = os.path.join(project_root, 'data', 'processed', 'ufc_etl.csv')\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "ufc_data = pd.read_csv(file_path)\n",
    "print(f\"Data successfully loaded: {df.shape[0]} rows, {df.shape[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c1712-e5f2-46c2-b41d-130f39b0fef4",
   "metadata": {},
   "source": [
    "## 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0fa52-2f28-4397-a1b5-98c994ddcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Get the KNN model from the model factory\n",
    "knn_model = model_factory.get_model('knn', X_train, y_train)\n",
    "\n",
    "# ðŸ”¹ Prediction with the KNN model\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# ðŸ”¹ Model evaluation using F1 score and other metrics through 'validate_model'\n",
    "accuracy, f1 = validate_model(knn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e7733-5a08-4eb3-af70-3d01de66b40c",
   "metadata": {},
   "source": [
    "## 4. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d09ea-718d-418b-a7c7-a0d2f64be037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ðŸ”¹ Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Fighter A\", \"Fighter B\"], yticklabels=[\"Fighter A\", \"Fighter B\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96f9c6-ec52-4466-a7e1-ce92d663a2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfourier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
